Uklanjanje NaN vrednosti iz trening skupa:
    1. nacin: prociscavanje podataka
        - ukloniti sve opservacije koje sadrze NaN, mana je sto gubimo podatke
        - probao sam: od 18351 ostane nam 18110 opservacija
    2. nacin: ukloniti obelezja sa nedostajucim vrednostima
        - 10/14 obelezja ima NaN vrednosti, pa mislim da ovo nije dobro resenje
    3. nacin: procena nedostajucih vrednosti
        - za kategoricka obelezja koristiti medijan, a za numericka sr.vrednost ili medijan
    4. nacin: koriscenje regresionom metodom, KNN, expectation-maximization

Obican RandomForestClassifier
    - score: 0.5033557046979866 na test_preview.csv


21.5.2020

-- vidi se neizbalansiranost klasa
-- ali distribucija klasa je jednaka i na treing i na test


AdaBoostClassifier(learning_rate=0.1, n_estimators=900) -- 0.55 na test_preview
    --> featureSelection sa 50 stabala je SPUSTIO score.


OBINCE METODE ---> pisem ih da bi znali od cega ansambl mora biti bolji..

    - obican SVM, sa C=2 dobije 0.523 znaci da je Ansambl ipak bolji..

    - obican SVM, sa C=2 kad se uradi normalizacija podataka i kad se selektuje 5 feature sa TreeBasedSelectorom
        dobije se 0.544

22.5.2020.

-- GradientBoosting je na cross validationu dao ovaj score
0.5621203754831585 za {'learning_rate': 0.2, 'n_estimators': 1500}

inace na test_preview je dostizao i do 0.60 za lr=0.1 i n_estimators=1300
na crossu: 0.5507454445057979 {'learning_rate': 0.1, 'n_estimators': 1300}


VotingClassifier -> test_preview 0.5234899328859061
                    cross_validation 0.5347874102705688 podeljen na 5

BaggingClassifier n_e 160 -> test_preview 0.5570469798657718
                    cross_validation 0.5275538376587521 podeljen na 5